\chapter{绪\hspace{6pt}论}

\section{研究工作的背景与意义}
\subsection{研究背景}
\label{subsec:intro-background}

随着信息技术产业的高速发展，数字信息量呈爆炸式增长。国际数据资讯公司（IDC）\cite{IDC}于2020年公布的统计及预测报告\cite{DataReport2020}显示，每年新产生的数据量在2015年至2025年间以约26\%的复合年增长率增长，预计仅2025年创建的新数据数据量将高达175.8\,ZB（而2015年仅为18.2\,ZB）。新创建数据量的快速增长导致个人及企业面临的数据存储和管理成本快速上涨\cite{敖莉2010重复数据删除技术}。另一方面，在各类型存储系统所保存的数据中，高达60\%的数据都是冗余的。并且，随着时间的推移，这些冗余数据占总数据量的比例将进一步上升\cite{mcknight2006digital}。近年来，存储系统中数据高度冗余的特点得到越来越多研究人员的关注，利用该特点来节省存储空间、降低存储管理开销是成为热门研究课题。

重复数据删除（data deduplication）\cite{付印金2012重复数据删除关键技术研究进展, 敖莉2010重复数据删除技术,xia2016Deduplication,Paulo2014} 是一种粗粒度数据压缩技术。传统数据压缩针对小规模数据（例如同一文件内部），使用字节级重新编码以降低冗余；而重复数据删除作用的基本单位是数据块（通常为8KiB），通过比较来自相同和不同文件的数据块，为具有相同内容的数据块仅保存一份物理拷贝以节约存储空间。如图~\ref{fig:Deduplication-storage-pattern}所示，在支持重复数据删除的各类存储系统（统称为重复数据删除系统）中，重复数据删除后的任何数据块都被一个或多个文件引用，而每个文件则以指向这些数据块的指针的集合形式进行存储。重复数据删除可为主存和备份数据分别节省50\%\cite{meyer11}和98\%\cite{wallace12}的存储空间，可显著降低云存储厂商的存储及维护成本\cite{付印金2012重复数据删除关键技术研究进展}。由于能够有效地降低存储开销，重复数据删除技术非常适合为管理日益增长的海量数据节省成本。在工业界，Dell EMC Data Domain\cite{EMCDataDomain}、Avamar\cite{Avamar}、Veritas的NetBackup Appliances\cite{veritas} 以及Commvault的开放数据平台\cite{CommVault} 都是较为知名的重复数据删除应用产品；此外，各大云存储厂商（例如 Dropbox\cite{Dropbox}、Google Drive\cite{GoogleDrive}、百度网盘\cite{BaiduPan}等）也纷纷将重复数据删除技术应用于各自的云服务产品中，以提升经济效益\cite{harnik2010side}。  

\begin{figure}[!htb]
    \small
    \centering
    \includegraphics[width=0.75\textwidth]{pic/DedupSystemStorageMode.eps}
    \caption{重复数据删除系统的存储模式} 
    \label{fig:Deduplication-storage-pattern}
\end{figure} 

\textbf{本文重点关注面向云环境的重复数据删除}。图~\ref{fig:Cloud-based-deduplication-storage-logic}描述了云环境重复数据删除系统框架。云服务商维护哈希索引表，记录所有已存储数据块的哈希值。在重复数据删除过程中，用户使用云存储客户端计算目标数据块的哈希值；云服务商检查该哈希值是否存在于数据块索引表中，如果哈希值存在（即云端已有目标数据块的副本），则更新目标数据块的所有权信息并通知客户端无需传输该数据块，从而同时节省传输带宽和存储空间（这种重复数据删除方式称为源端重复数据删除（source-based deduplication））。然而，由于重复数据删除系统中任意重复数据块均只保留一个副本，任意一个数据块的泄露可能扩散影响到共用该数据块的所有文件。这种文件共用数据块的存储模式强调了数据块的敏感性。因此，如何保护重复数据删除后的数据的隐私，成为云存储服务商应用重复数据删除技术亟需解决的关键问题。

\begin{figure}[!htb]
    \small
    \centering
    \includegraphics[width=\textwidth]{pic/Cloud-deduplication.pdf}
    \caption{云环境重复数据删除系统结构} 
    \label{fig:Cloud-based-deduplication-storage-logic}
\end{figure} 

近年来，研究者提出加密后重复数据删除\cite{bellare2013MLE}以保护重复数据删除过程中的数据安全。图~\ref{fig:Cloud-based-encrypted-deduplication-storage-logic}描述了加密后重复数据删除系统框架，其包括客户端和云服务端两个主要组成部分。为了防止云服务商获取外包数据内容，加密后重复数据删除系统在客户端部署消息锁加密（MLE：message-locked encryption）\cite{bellare2013MLE}以加密明文数据块（简称为明文数据块），同时确保重复数据删除仍然能够作用于密文数据块（简称为密文数据块）以节约存储空间。传统对称加密算法为每个客户端或每个数据块分配不同加密密钥，导致相同的明文数据块被加密为不同的密文数据块，无法通过重复数据删除进行冗余消除。消息锁加密的核心思路时基于数据块内容产生密钥（称为MLE密钥，例如MLE密钥为明文数据块的哈希值\cite{douceur02}），从而将相同明文数据块加密为相同的密文数据块，以兼容直接针对密文数据块的重复数据删除。现有消息锁加密采用服务器辅助密钥生成方式（称为服务器辅助消息锁加密（Server-aided MLE）
\cite{bellare2013DupLESS}），即部署第三方密钥服务器管理全局秘密，同时基于明文数据块哈希值以及密钥服务器的全局秘密共同生成MLE密钥，以防止攻击者针对MLE密钥实施离线暴力破解攻击。

\begin{figure}[!htb]
    \small
    \centering
    \includegraphics[width=\textwidth]{pic/Cloud-encrypted-deduplication-logic.pdf}
    \caption{面向云环境的加密后重复数据删除系统框架}
    \label{fig:Cloud-based-encrypted-deduplication-storage-logic}
\end{figure}

另一方面，重复数据删除受到伪造数据所有权的攻击威胁\cite{harnik10,mulazzani11}。由于云服务商仅基于收到的数据块哈希值判断客户端是否拥有相应数据块，恶意用户/客户端可以伪造任意密文数据块的哈希值，如果该密文数据块已在云端存储（即已发生重复数据删除），则恶意客户端无需传输密文数据块内容便可获得相应密文数据块的访问权限。为了防止伪造所有权攻击，加密后重复数据删除增加了所有权证明（proof-of-ownership）技术\cite{halevi11}：除了密文数据块的哈希值以外，云服务商要求客户端额外提交目标密文数据块的所有权证明（proof）；云服务商首先基于证明验证该客户端是否真实且完整拥有相应密文数据块，然后再执行如前所述的重复数据删除过程。所有权证明技术的合理性在于，只针对客户端真实拥有（即具有完整访问权限）的密文数据块执行重复数据删除，从而避免非法访问其他客户端已在云端存储的内容。

然而，支持数据块所有权证明技术的加密后重复数据删除依然不足以完全击败恶意客户端，恶意客户端仍可通过枚举数据块内容以发起推测内容攻击（{\em learning-content attack}）\cite{harnik10, zuo2018mitigating}。具体来说，攻击者对目标文件具有相当的先验知识，了解目标文件（例如，来自同一家公司的录用通知书）的大部分格式化内容，并旨在识别其他客户拥有的目标文件的私有部分（例如，录用通知书中的签约工资和入职奖金数额）。攻击者通过枚举目标文件中私有内容的可能值来伪造大量文件，对每个伪造的文件执行源端重复数据删除，进而在某些伪造的文件无需上传任何内容时推断出目标文件中的隐私信息（即当前伪造文件所包含的内容）。

\subsection{问题和动机}
\label{subsec:intro-problem}

现有面向云环境的加密后重复数据删除系统面临着系统效率低与安全性不足的双重挑战：

\subsubsection{系统效率} 
\label{subsec:intro-problem-performance}

在服务器辅助密钥生成过程中，现有加密后重复数据删除系统（图~\ref{fig:Cloud-based-encrypted-deduplication-storage-logic}）须使用基于盲签名\cite{armknecht2015transparent,bellare2013DupLESS}的无记忆伪随机函数（OPRF：oblivious pseudorandom function）生成密钥\cite{bellare2013DupLESS}，以防止密钥服务器获得明文块的哈希值。同时，为了实现所有权证明，系统须在云服务端维护Merkle哈希树，并基于哈希树验证客户端提交的证明信息\cite{halevi2011proofs}。项目组指出，服务器辅助密钥生成和所有权证明的密码操作是加密后重复数据删除系统的主要效率瓶颈。

为了验证以上论断，项目组基于图~\ref{fig:Cloud-based-encrypted-deduplication-storage-logic}框架和现有技术方案实现了加密后重复数据删除系统的基础原型。基础原型支持基于RSA\cite{bellare2013DupLESS}或BLS\cite{armknecht2015transparent}盲签名生成密钥，以及基于Merkle哈希树\cite{halevi2011proofs}或通用哈希（universal hash）\cite{xu2013weak}证明所有权（注：基于通用哈希的所有权证明方法\cite{xu2013weak}只能达到较低安全性）。


\begin{table}[!htb]
    \small
    \centering
    \begin{tabular}{@{}ccc@{}}
    \toprule
                           & 处理阶段/可选方案          & 处理时间（ms/MiB） \\ \midrule
                           & 数据分块               & 3.8          \\
    服务器辅助密钥生成              & RSA盲签名方案（BLS盲签名方案） & 40.7(488.3)  \\
    \multirow{3}{*}{所有权证明} & 数据加密               & 2.5          \\
                           & 哈希树方案（通用哈希方案）      & 27.0(7.2)    \\
                           & 重复数据删除             & 1.7          \\ \bottomrule
    \end{tabular}
    \caption{基础原型每个步骤处理1MiB数据的时间开销：括号内为可供备选的服务器辅助密钥生成方案和所有权证明方案，以及相应处理时间}
    \label{tab:intro-bottleneck}
\end{table}

表~\ref{tab:intro-bottleneck}展示了基础原型每个步骤处理1MiB数据的平均时间开销。服务器辅助密钥生成是最大效率瓶颈。如果采用基于Merkle哈希树的所有权证明方案，RSA盲签名和BLS盲签名分别占系统总开销的53.8\%和93.3\%。同时，所有权证明也是限制系统效率的重要因素，如果采用基于RSA盲签名的服务器辅助密钥生成方案，Merkle哈希树和（较低安全性的）通用哈希方案分别占系统总开销的35.7\%和9.5\%。

\subsubsection{安全隐患} 
\label{subsec:intro-problem-security}

在重复数据删除过程中，云服务商通知客户端传输或不传输密文块内容（\S\ref{subsec:intro-background}） ，实质上泄漏了“其他客户端是否已经存储相应密文块”的侧信道信息（side-channel information）。虽然所有权证明阻止了针对非授权密文块的重复数据删除，但不足以防止恶意客户端的侧信道攻击。
例如，攻击者可以枚举所有可能的数据内容，并利用重复数据删除泄漏的侧信道信息实施推测内容攻击（learning-content attack）\cite{harnik10,zuo2018mitigating}。假设攻击者已知某个客户端持有目标文件且文件内容符合固定的公开格式（例如工资条、合同等模版化数据），致力于推断目标文件未公开的敏感内容（例如薪水金额）。攻击者枚举所有可能的未公开内容，并通过恶意客户端上传所生成的枚举文件。如果上传某个枚举文件时无需传输任何密文块，即可推断该枚举文件即为目标文件。此时，由于攻击者完全获得了所枚举文件的访问权限，仅检测所有权无法阻止推测内容攻击。
项目组扩展现有工作\cite{harnik10,zuo2018mitigating}，设计案例验证推测内容攻击的可行性。考虑Alice和Bob为应届毕业学生，同时收到某公司的雇佣合同。他们将各自合同备份至云端。假设Alice为攻击者，通过推测内容攻击推断Bob合同中的薪水和签字费。

\begin{table}[!htb]
    \small
    \centering
    \begin{tabular}{@{}cccc@{}}
    \toprule
    测试环境 & 上传次数                            & 上传流量（MiB）                       & 攻击时间（秒）        \\ \midrule
    局域网  & \multirow{2}{*}{841.0 $\pm$ 608.3} & \multirow{2}{*}{7.4 $\pm$ 5.4} & 105.0 $\pm$ 76.1 \\
    阿里云  &                                 &                                 & 475.5 $\pm$ 339.8 \\
    \bottomrule
    \end{tabular}
    \caption{推测内容攻击开销：以上结果包含十次测试数据基于T分布的95\%置信区间}
    \label{tab:intro-bottleneck}
\end{table}

为了实现以上案例，项目组基于Google合同模版\cite{GoogleOffer}，更改其中姓名、年薪（假设为6K的倍数\cite{harnik10}，介于204K和804K之间）和签字费（假设为10K的倍数，介于300K和600K之间）以生成Alice和Bob的合同，每个合同约占18.5KiB。项目组随机生成Bob的薪水和签字费，并通过基于图~\ref{fig:Cloud-based-encrypted-deduplication-storage-logic}设计实现的基础原型将Bob的合同存储至服务端。令Alice基于自身合同作为内容模版，枚举Bob所有可能的薪水和签字费，以实施推测内容攻击。项目组分别在本地局域网（客户端、密钥服务器和服务端均部署在具有10Gb/s网速的本地实验环境）和阿里云（在本地部署客户端和密钥服务器，在阿里云部署服务端）实现上述攻击。Alice需上传大约841份伪造合同，消耗7.4MiB网络流量（包括传输非重复密文块和元数据），在局域网和阿里云环境中推断Bob的隐私信息分别只需105.0秒和475.5秒。

\subsection{研究内容概述}
\label{subsec:intro-target}

如前所述（\S\ref{subsec:intro-problem}），现有面向云环境的加密后重复数据删除存在密钥生成效率低、所有权证明计算复杂、易于遭受推测内容攻击等不足。本研究拟改进现有的加密后重复数据删除方法，提出：

\begin{enumerate}
    \item 基于TEE的轻量级密钥生成技术，以提升服务器辅助密钥生成的效率和可扩展性。
    \item 基于TEE的高效所有权证明技术，以提升所有权证明效率。
    \item 基于TEE的扩展所有权证明技术，以进一步防止推测内容攻击（现有所有权证明技术不足以防止推测内容攻击，见\S\ref{subsec:intro-problem-security}）。
\end{enumerate}

\subsection{研究意义}
\label{subsec:intro-meaning}

在学术界，自收敛加密\cite{douceur02}提出以来，安全重复数据删除已有20余年研究历史，但由于一些本质问题（例如效率、侧信道攻击、密钥管理等，见\S\ref{subsec:intro-problem}）未能得到妥善解决而难以落地推广；并且，目前的学术研究聚焦于解决某一方面本质问题，同时以牺牲另一方面性能为代价（\S\ref{sec:compare-deduplication}）。本研究的学术研究意义在于，突破基于TEE的安全重复数据删除方法，同时妥善解决效率、安全、存储多个本质问题，推动安全重复数据删除理论到实践的转化。并且，本研究作为TEE在数据存储领域的应用范例，所提出的系统和方法对TEE在其他领域研究具有参考价值。

在工业界，本研究研究的安全、效率、成本问题是云服务商关注的焦点问题。一方面，数据安全隐私和服务使用体验，是决定用户是否选择云服务的关键因素；另一方面，重复数据删除有助于降低设备购置和维护成本，提升云服务商的经济效益。因此，本研究的应用实践价值在于，在服务商关注的安全、效率、成本维度，研究的系统和方法将全面领先于现有基于纯软件的安全存储解决方案，将推动未来基于TEE的云存储架构，对促进云服务产业发展具有积极意义。

\section{国内外研究历史与现状}
\label{sec:compare}

\subsection{加密后重复数据删除}
\label{subsec:compare-deduplication}

\S\ref{subsec:intro-problem}列举了加密后重复数据删除系统面临的系统效率、安全隐患方面的不足，接下来将综述现有的针对性解决方法及与本研究研究内容的区别。

\subsubsection{系统效率}
\label{subsubsec:compare-deduplication-performance}

为了解决服务器辅助密钥生成效率瓶颈，SecDep\cite{zhou2015secdep}提出生成粗粒度的文件级MLE密钥，并针对不同用户之间的相同数据使用文件级重复数据删除；项目组提出了基于相似性密钥生成方法\cite{qin17}，为若干个连续明文块生成基于代表性明文块（例如其中具有最小哈希值的明文块）的MLE密钥，用以加密其中的每个明文块。以上方法均是通过减少MLE密钥生成次数来解决效率问题，但导致部分相同明文块被加密为不同密文块而无法被删除。本研究研究的基于TEE的轻量级密钥生成技
术将提升单次密钥生成速率，同时允许删除所有数据块级冗余；研究的加密前重复数据删除方法无需通过服务器辅助方式生成密钥。
在所有权证明方面，研究者通过降低安全性提升效率\cite{xu2013weak,pietro12}，但是，本研究研究的基于TEE的扩展所有权证明技术将同时提升所有权证明的安全性和效率。

\subsubsection{安全隐患}
\label{subsubsec:compare-deduplication-security}

为了防止推测内容攻击，现有方法包括：

\begin{enumerate}
    \item \textbf{目标端重复数据删除（target-based deduplication）}\cite{harnik10}强制客户端传输所有密文块后在服务端删除重复密文块。
    \item \textbf{随机阈值重复数据删除（randomized-threshold deduplication）}\cite{harnik10}为每个密文块分配一个随机阈值，如果密文块被上传次数超过阈值，则执行源端重复数据删除（\S\ref{subsec:intro-background}），否则执行目标端重复数据删除。
    \item \textbf{两阶段重复数据删除（two-stage deduplication）}\cite{li2015cdstore}针对来自同一客户端的密文块采取源端重复数据删除，不同客户端的密文块采取目标端重复数据删除。
\end{enumerate}

以上方法均须传输全部（目标端重复数据删除）或部分（随机阈值重复数据删除和两阶段重复数据删除）重复数据，增加带宽开销。本研究研究的基于TEE的扩展所有权证明技术兼容源端重复数据删除而无需传输重复数据。 

除推测内容攻击以外，消息锁加密将相同明文块加密为相同密文块（\S\ref{subsec:intro-background}），泄漏了数据块频率（即每个数据块在总体数据中的出现次数）而易于受到频率分析攻击威胁。项目组针对频率分析的攻击和防御开展了深入研究：在攻击方面，构造了基于数据局部性攻击方法，表明消息锁加密产生的密文块的原始内容不仅易于被推测分析\cite{li2020Info}，并且攻击者还能以较高概率判断所推测内容的正确性\cite{li2022revisiting}；在防御方面，提出了可调节加密重复数据删除\cite{li2020balancing}，实现了频率保护-存储性能的可控平衡。本论文所研究的加密后重复数据删除兼容可调节加密技术，以抵御频率分析攻击。

\subsection{基于TEE的安全应用}
\label{subsec:compare-tee}

TrustZone和SGX是目前应用最广泛的TEE解决方案\cite{pinto19}。TrustZone是ARM CPU的硬件安全扩展，主要应用于低功耗移动平台以保护敏感应用程序的执行逻辑\cite{rubinov2016automated}、用户输入口令\cite{ying2018truz}，以及监控安全区以外的程序执行\cite{azab2014hypervision}。SGX是Intel CPU指令集的安全监控扩展，已被广泛用于加强不同应用系统的安全性，包括比特币\cite{matetic19}、文件系统\cite{ahmad2018OBLIVIATE,shinde20}、外包数据库\cite{eskandarian17,priebe18,sun21}、键值存储\cite{mishra18,bailleu2019SPEICHER,kim19,bailleu2021Avocado}和数据分析平台\cite{schuster15, zheng2017Opaque, bowe2020ZEXE}等。

此外，SGX \cite{sgx} 已被广泛用于保护存储系统。PESOS \cite{krahn18} 使用 SGX 强制执行对象存储的访问策略。 OBLIVIATE \cite{ahmad2018OBLIVIATE} 增强了基于 SGX 的文件系统对特权侧信道攻击的安全性。 EnclaveDB \cite{priebe18} 和 ObliDB \cite{eskandarian19} 保护外包数据库免受 SGX 信息泄露。 NEXUS \cite{djoko19} 通过 SGX 对不受信任的云存储启用细粒度的访问控制。在性能方面，Harnik等人\cite{harnik18} 提出了减轻 SGX 实现的性能开销的指南。 ShieldStore \cite{kim19} 实现特定于应用程序的数据管理以限制安全区内存使用。 SPEICHER \cite{bailleu2019SPEICHER} 是一个基于 SGX 的基于 LSM 的键值存储，具有高效的 I/O 操作。以上所有研究均未考虑重复数据删除。Dang等人\cite{dang17} 提出了基于代理的协议，用于带宽高效的加密后重复数据删除，但这些协议没有解决密钥生成性能开销，也没有实现。SPEED \cite{cui19} 利用重复数据删除来提高 SGX 计算的效率，但 \sysnameS 使用 SGX 提高了加密后重复数据删除的性能。其他研究使用云端安全区进行 PoW 验证 \cite{you2020Proofs} 和安全的基于文件的重复数据删除 \cite{fuhry20}，而 \sysnameS 使用客户端安全区进行有效的 PoW 证明生成并支持更细粒度的块-基于重复数据删除。S2Dedup \cite{miranda21} 管理一个云端安全区来执行安全的重复数据删除，但它依赖于客户端完全受信任的假设。SeGShare\cite{fuhry2020segshare}在服务端部署安全区实现文件级重复数据删除，但无法删除相似文件中的相同数据块。S2Dedup\cite{miranda21}在服务端部署安全区以重加密来自不同客户端的密文块，并在安全区外执行针对重加密后密文块的重复数据删除，但是，由于所有数据块的重复数据删除均需进出安全区，S2Dedup导致严重的CPU环境切换开销（context-switching overhead）\cite{weisse2017regaining}。

\section{本文的主要贡献与创新}
我们提出了 \sysnameS，这是一个基于 SGX 的高性能加密后重复数据删除系统。 \sysnameS 建立在 {\em DupLESS} \cite{bellare2013DupLESS} 中的服务器辅助密钥管理之上，但在安全区内执行高效的加密操作。实现 \sysnameS 的设计具有不小的挑战。首先，安全地引导安全区以托管受信任的代码和数据至关重要，但证明安全区的真实性会导致显着延迟。其次，每个客户端都需要通过安全通道与密钥管理器内部的安全区进行通信，但安全通道的管理开销会随着客户端数量的增加而增加。最后，客户端可以续订或撤销云服务订阅，因此允许动态客户端身份验证至关重要。为此，我们为 \sysnameS 实现了三个主要构建块: 

\begin{itemize}[leftmargin=*]
    \item \textit{安全高效的安全区管理}:
        它可以防止密钥管理器受到破坏，并允许客户端在重新启动后快速引导安全区。
    \item \textit{自更新盲密钥管理}:
        它基于密钥回归 \cite{fu06} 生成一个盲密钥，用于保护密钥管理器内的安全区和每个客户端之间的通信，以便可以更新盲密钥以进行动态客户端身份验证。
    \item \textit{基于 Intel SGX的推测性加密}:
        它通过推测性加密 \cite{eduardo19} 减轻了安全通道管理的在线加密/解密开销。
\end{itemize}

我们广泛表明 \sysnameF 可以有效地检测学习内容攻击（例如，在我们的案例研究中，概率至少为 98.6\%），而误判的数量很低（例如，\sysnameF 的默认配置中为零）。此外，我们将 \sysnameF 部署到现有的面向性能的系统 SGXDedup \cite{ren21} 中，以提高其对学习内容攻击的安全性。请注意，SGXDedup 基于 TEE 构建，可将之前的加密后重复数据删除系统 \cite{bellare2013DupLESS} 加速八倍以上，而我们的 \sysnameF 部署系统，即 \prototype 相比 SGXDedup 的性能开销低至 8.8\% 和 0.8\%分别是大规模真实世界数据的上传和下载。

\section{本论文的结构安排}
