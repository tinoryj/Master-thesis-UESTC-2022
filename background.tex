\chapter{相关基础研究}
\label{chapter:background}

本章将介绍普通和加密后重复数据删除、可信执行环境(TEE)等本文利用的基础知识，以及加密后重复数据删除系统中存在的性能瓶颈和安全性隐患。

\section{重复数据删除}
\label{sec:background-deduplication}

本文专注于基于数据块的重复数据删除，它以称为数据块的小型数据单元为粒度运行。基于数据块的重复数据删除比基于文件的重复数据删除更精细，因此通常具有更高的存储效率(节省更多的存储空间)。

基于数据块的重复数据删除有以下两种基本的数据块分块方法：

\begin{itemize}[leftmargin=*]
    \item \textbf{固定大小的数据分块(Fixed-size chunking)}，通常将文件划分为固定长度的数据块，具有简单快速的特点，但文件中小范围修改(例如：增加1字节内容或删除1字节内容)将从修改位置开始影响后续所有数据块的内容，不利于重复数据删除。
    \item \textbf{可变大小的数据分块(Variable-size chunking)}，也称为内容定义的数据块分块(Content-defined chunking)。通常采用内容相关的方式指定数据块的边界(例如，通过Rabin指纹\cite{rabin1981fingerprinting}在特定内容模式出现时进行分块)。因此，在文件发生小范围修改时，产生的大多数数据块仍可保持不变，使得重复数据删除系统存储效率得到保障。
\end{itemize}

在多数备份系统工作负载\cite{zhu2008avoiding,lillibridge2009sparse}下，可变大小的数据分块方案通常可以获得更优的存储效率，但在某些特定工作负载(例如，VM备份数据集\cite{jin2009effectiveness})下，固定大小的数据分块方案却更加有效。本文的工作可兼容固定大小和可变大小的数据分块方法产生的数据块。

\begin{figure}[!htb]
    \small
    \centering
    \includegraphics[width=\textwidth]{chunk-based-dedup-arch.pdf}
    \caption{基于数据块的重复数据删除的工作流程概览}
    \label{fig:chunk-based-dedup-flow}
\end{figure}

图\ref{fig:chunk-based-dedup-flow}总结了基于数据块的重复数据删除工作流程。具体地，重复数据删除系统首先通过数据分块过程将客户端的文件(例如，备份文件)分割为逻辑数据块，根据每一个逻辑数据块的内容,使用哈希算法计算得到其对应的唯一标签(又称为指纹)。如果两个数据块具有相同的指纹，则认为两个数据块内容相同(不同逻辑数据块计算得到相同指纹的概率可忽略不计\cite{black2006compare})；若两个逻辑数据块指纹不一致，则认为两逻辑数据块不同。重复数据删除系统仅存储相同逻辑数据块的唯一副本(称为物理数据块)，并且每个相同的逻辑数据块仅通过一个空间开销较小的索引指向相同的物理数据块。此外，基于数据块的重复数据删除系统记录文件所拥有的所有逻辑数据块的信息作为该文件的元数据，用于文件读取、删除等操作。

重复数据删除技术根据重复数据删除操作发生的位置可分为源端重复数据删除及目标端重复数据删除\cite{IDC2010Data}：

\begin{itemize}[leftmargin=*]
    \item \textbf{源端重复数据删除(Source-based Deduplication)}由客户端计算目标数据块的哈希值，并由服务端检查该哈希值是否存在于索引表中。如果哈希值存在(即服务端已有目标数据块的副本)，则通知客户端无需传输目标数据块。
    \item \textbf{目标端重复数据删除(Target-based Deduplication)}强制客户端传输所有密文数据块，并在服务端对所有收到的密文数据块进行重复数据删除。
\end{itemize}

源端重复数据删除技术可有效节省网络流量资源，可显著降低云服务商提供存储服务的成本，但泄露了“其他客户端是否已经存储相应密文数据块”的侧信道信息(参见\S\ref{subsubsec:intro-problem-security})；目标端重复数据删除具有更高的隐私保护能力，但产生大量网络资源浪费，并显著增加了服务端计算开销。本文关注网络资源开销较小的源端重复数据删除技术，并通过TEE技术解决其存在的性能和安全性问题。

\section{安全重复数据删除}
\label{sec:background-enc-deduplication}

加密后重复数据删除解决了外包环境(例如，云存储)中的数据块机密性保障问题，同时保持了重复数据删除的有效性。出于安全因素考虑，用户希望将自己的数据加密后再进行外包存储，以确保个人数据隐私性。传统对称加密算法算法为每个客户端或每个逻辑数据块分配独立的加密密钥，使得来自不同(或相同)客户端的相同的逻辑数据块被加密为不同的密文数据块，服务器无法感知这些密文数据块所对应的明文数据块内容是否一致，使得针对外包数据的重复数据删除完全失效。

\begin{figure}[!htb]
    \small
    \centering
    \includegraphics[width=\textwidth]{chunk-based-enc-dedup-arch.pdf}
    \caption{基于数据块的加密后重复数据删除的工作流程概览}
    \label{fig:chunk-based-enc-dedup-flow}
\end{figure}

如图~\ref{fig:chunk-based-enc-dedup-flow}所示，基于内容的密钥生成方法给加密后重复数据删除提供了新的处理思路。最基本的基于内容的密钥生成方法的实例化是基于明文数据的内容(例如，基于重复数据删除中的逻辑数据块)导出其对称加密密钥，并使用该密钥加密明文数据以形成对应的密文数据(例如，加密的逻辑数据块)。因此，使用基于内容的密钥生成方法为任意逻辑数据块产生对称加密密钥可以确保将相同的明文数据块加密为相同的密文数据块。最后，存储系统从每个密文数据块中导出其对应的指纹并执行重复数据删除。相较于普通重复数据删除，加密后重复数据删除需额外保存用户文件所包含数据块的密钥元数据，并由各个客户端进行加密以防止服务端取得相应数据块的明文内容。

\subsection{数据块加密技术}
\label{subsec:background-encrypted-deduplication-key}

\textit{消息锁加密(Message-Locked Encryption, MLE)}\cite{bellare2013MLE}将基于内容的密钥生成方案等加密原语形式化用于加密后重复数据删除。它指出了如何从明文数据块的内容导出相应的对称加密密钥(称为 \textit{消息锁加密密钥(MLE密钥)})。以最广泛使用的消息锁加密技术：收敛加密(Convergent Encryption, CE)\cite{douceur2002reclaiming}为例，CE使用明文数据块的安全哈希作为MLE密钥，使得相同的明文数据块可被加密为相同的密文数据块，从而令重复数据删除技术在密文数据块之上仍然可行。除此之外，基于CE的消息锁加密方案还包括：

\begin{enumerate}[leftmargin=*]
    \item \textbf{哈希收敛加密(Hash Convergent Encryption, HCE)}\cite{douceur2002reclaiming}与CE具有相同的MLE密钥产生规则，但基于明文哈希值计算指纹用于重复数据删除(CE使用密文指纹进行重复数据删除)。
    \item \textbf{随机收敛加密(Random Convergent Encryption, RCE)}\cite{douceur2002reclaiming}使用随机密钥加密明文以产生非确定的密文，但基于明文的哈希值进行重复数据删除检查。
    \item \textbf{收敛扩散(Convergent Dispersa, CD)}\cite{li2016cdstore}使用明文哈希值作为秘密共享(Secret Sharing)的输入种子，并对产生的多个秘密共享分别计算哈希并进行重复数据删除，在兼容重复数据删除的基础上提高了密文存储的可靠性。
\end{enumerate}

然而，CE容易受到\textbf{离线暴力破解攻击}的威胁。这是由于CE的MLE密钥(即明文数据块的哈希)可以自由产生。具体来说，攻击者通过枚举所有可能的明文数据块的MLE密钥来从目标密文数据块(其加密密钥未知)推断输入的明文数据块，以检查是存在某个明文数据块被加密到目标密文数据块。

服务器辅助消息锁加密(Server-aided MLE)\cite{bellare2013DupLESS}是最先进的加密原语，可增强加密后重复数据删除对离线暴力攻击的安全性。它为消息锁加密中的MLE密钥生成步骤部署了一个专用的\textbf{密钥服务器(key server)}。为了加密明文数据块，客户端首先将明文数据块的指纹发送到密钥服务器，密钥服务器通过指纹和密钥服务器维护的\textbf{全局秘密(global secret)}返回MLE密钥。如果全局秘密是安全的，则攻击者无法发起离线暴力攻击；如果全局秘密被泄露，则其安全性会降低到原始消息锁加密的安全性。服务器辅助消息锁加密建立在如下两种安全机制之上：

\begin{itemize}[leftmargin=*]
    \item \textbf{遗忘伪随机函数(oblivious pseudorandom function, OPRF)}\cite{naor2004Number}是一种安全计算协议，协议包含服务端和客户端，服务端持有密钥$k$，客户端持有输入$x$，双方通过交互来联合计算函数$f_k(x)$，最终由客户端得到函数值。OPRF的计算过程以盲化方式进行,即在计算过程中服务端无法获取关于$x$的任何有价值信息，同时客户端无法获取关于$k$的任何有价值信息。
    \item \textbf{速率限制(Rate-limiting)}\cite{bellare2013DupLESS}阻止特定操作频率超出某些限制。在大型系统中，速率限制通常用于保护底层服务和资源。
\end{itemize}

基于遗忘为随机函数，密钥服务器可依据客户端发送明文数据块的“盲化指纹”，进而基于盲指纹和全局秘密产生对应数据块的“盲化密钥”，阻止了密钥服务器了解明文数据块信息；并使得客户端可在不了解密钥服务器所拥有的全局秘密的条件下获得目标明文数据块的MLE密钥。对来自客户端的密钥生成请求进行速率限制，进一步防止恶意客户端向密钥服务器发出海量密钥生成请求以获得目标MLE密钥，限制了攻击者暴力破解攻击的速度。

\subsection{数据所有权证明技术}
\label{subsec:background-encrypted-deduplication-pow}

为了节省宝贵的网络带宽资源，现有加密后重复数据删除系统普遍采用源端重复数据删除，以便在客户端删除重复数据块，而无需上传到服务端(\S\ref{sec:background-deduplication})。但是，源端重复数据删除导致“目标数据块是否已在服务端存储”的侧信道信息，使得某些客户端存在恶意时，源端重复数据删除很容易受到侧信道攻击(\textit{Side-channel Attack})\cite{harnik2010side,halevi11}的影响。

一种典型的侧信道攻击被称为\textbf{伪造所有权攻击}：恶意客户端未授权访问其他客户端存储的数据块\cite{harnik2010side,mulazzani11}。具体来说，由于服务端仅能基于收到的数据块哈希值判断客户端是否拥有对应的数据块，攻击者可使用任意目标密文数据块的指纹来说服服务端其是该目标数据块的所有者，进而获得该数据块的完全访问权限(\S\ref{subsec:intro-background})；另一种侧信道攻击被称为\textbf{推测内容攻击}：恶意客户端将目标密文数据块指纹发送到服务端以检查该数据块是否存在(例如，目标密文数据块对应于某个可能的密码\cite{harnik2010side})，以此识别来自其他客户端的敏感信息(\S\ref{subsubsec:intro-problem-security})。

现有防御机制尚无法在执行源端重复数据删除且不大量增加额外网络带宽资源开销的前提是防御推测内容攻击。而为了防止伪造所有权攻击，源端加密后重复数据删除增加了所有权证明(proof-of-ownership, PoW)机制\cite{halevi11}，要求客户端额外向服务端提交目标密文数据块的所有权证明(proof)，且仅在所有权证明成功的条件下进行重复数据删除。所有权证明机制可使得服务端只针对客户端真实拥有(即具有完整访问权限)的密文数据块执行重复数据删除，避免了攻击者非法访问其他客户端已在云服务端存储的内容。现有基于默克尔树(Merkel Tree)的所有权证明机制(称为POW-MT)\cite{xu2013weak}使用纠删码对数据块进行编码，随后在纠删码编码结果的基础上建立默克尔树用于所有权证明。而另一种基于通用哈希函数(Universal Hash)的所有权证明机制(称为POW-UH)\cite{halevi2011proofs} 相较于基于默克尔树的所有权证明机制拥有更高的效率，但降低了安全性假设。

本文关注网络和服务端计算资源开销较小的源端重复数据删除技术，并通过TEE技术解决其存在的密钥生成和所有权证明效率问题，以及易受到推测内容攻击的安全性问题。

\section{可信执行环境(TEE)}
\label{sec:background-tee}

TEE全名为可信执行环境(Trusted Execution Environment)是计算平台上由软件协同硬件方法构建的一个安全区域，可以确保在安全区域内加载的程序和数据在完整性和机密性方面得到必要保护。其目标是确保目标程序按照预期执行，保证程序初始状态和运行时状态的机密性、完整性。针对TEE的相关概念及规范定义，各个软件、硬件厂商结合自己的基础架构形态产生的具体实现各不相同。虽然在技术实现上存在显著差异，但TEE的技术共同点可总结为如下三点：

\begin{itemize}[leftmargin=*]
    \item \textbf{隔离性}：
          TEE通过隔离的程序执行环境，提供一个可信的执行空间，为其中运行的程序和存储的数据提供了机密性和完整性保护。X86架构的隔离机制从Intel 80286处理器开始，Intel提出了CPU的两种运行模式，并且逐步衍生出后来的不同的特权界别，再后来提出了安全区域范围更小的SGX机制实现可信执行环境(TEE)；同样的，ARM架构通过TrustZone技术实现了相关软硬件的隔离性，实现了安全世界(Secure World)与非安全世界(Normal World)的隔离。
    \item \textbf{软硬协同性}：
          虽然标准定义可以通过单独软件方式或单独硬件方式实现TEE，但实际应用场景下，行业内更多选择通过软硬件结合的方式进行TEE的设计。
    \item \textbf{富表达性}：
          与传统安全新芯片或纯软件的密码学营私保护方案相比，TEE支持的上层业务表达性更强，软件开发者仅需要根据业务逻辑划分业务层面的隐私和非隐私区域，而不会对定义隐私区域内的算法逻辑的语言等有可计算性方面的限制(图灵完备的)。同时，由于TEE为程序提供了可信的执行环境，安全区内的数据无需进行密态运算，使得TEE应用可以支持更多的算计及复杂的算法。
\end{itemize}

\subsection{Intel SGX}
\label{subsec:background-tee-sgx}

\begin{figure}[!htb]
    \small
    \centering
    \includegraphics[width=0.6\textwidth]{sgx-example.pdf}
    \caption{Intel SGX框架}
    \label{fig:sgx-arch}
\end{figure}

Intel Software Guard Extensions (Intel SGX)\cite{sgx,sgx2}，是一组内置于现代Intel CPU中用于增强应用程序代码和数据安全性的扩展指令。开发者可利用SGX技术将应用程序的安全操作封装在称为“安全区(Enclave)”的硬件保护环境中，保障用户关键代码和数据的机密性和完整性。Intel SGX最关键的优势在于将应用程序以外的软件栈如操作系统(OS)和基本输入输出系统(BIOS)都排除在了可信计算基(Trusted Computing Base, TCB)之外，一旦程序和数据在安全区之中，即便是操作系统和也无法影响安全区内的代码和数据，安全区的安全边界只包含CPU和它本身(如图\ref{fig:sgx-arch}所示)。Intel SGX具有隔离、证明和密封三项主要安全功能。

\textbf{隔离(Isolation)}：安全区代码和数据被放置在被称为\textit{enclave page cache (EPC)}的硬件内存保护区域中，该内存区域使用内存加密引擎(MEE)进行加密，以防止泄露任何内存数据到本安全区之外。EPC以大小为4\,KiB的页面为基本单位管理安全区内存，任意安全区内应用程序最多可占用96\,MiB内存空间\cite{harnik2018SGX}。当安全区内存使用超过上限时，须将未使用的内存页面加密并逐出到未受保护的主存，并在将逐出的页面加载回安全区内存时解密并验证完整性，导致巨大的分页开销\cite{arnautov2016SCONE,dinhngoc2019Everything}。

此外，SGX为安全区和未受保护的内存之间的交互提供了两个接口，应用程序可以通过安全区内部调用(ECalls)进入安全区以执行安全区内部函数，并且在ECall中，程序可通过安全区外部调用(OCalls)暂时退出安全区并调用不受保护的内存中的不受信任的函数。但安全区内部调用和外部调用会产生大量的CPU上下文切换开销\cite{harnik2018SGX}，严重影响SGX应用程序性能。

\textbf{认证(Attestation)}：SGX安全区支持本地认证(Local Attestation)和远程认证(Remote Attestation)，以确保安全区内运行的程序未被修改。特别的，在远程认证过程(参见\cite{SGX-RA}提供的端到端远程认证示例)中，远程实体(例如，服务端)需要联系Intel运营的证明服务来检查目标安全区提供的安全区相关信息的完整性和正确性。随后，远程实体通过将其收到的安全区信息与目标安全区中预期的可信信息进行比较来验证目标安全区是否未被修改。然而，由于远程认证需要Intel服务器的支持，远程认证过程通常导致较高且不可控的时间开销。

\textbf{密封(Sealing)}： SGX安全区通过密封在安全区内容需要在安全区外持久化存储时进行保护。它使用目标安全区专用的密封密钥(Sealing key)在数据被移出安全区之前进行加密。密封密钥可以从安全区测量哈希(Measurement hash，即安全区内容的SHA-256哈希)或安全区的创建者提供的签名身份派生。基于前者产生的密封密钥仅有目标安全区本身可以导出，而基于后者产生的密封密钥可有同一开发者创建的各个不同的安全区导出。因此，仅有相应的安全区才能获得正确的密封密钥并解密密封数据。

\subsection{ARM TrustZone}
\label{subsec:background-tee-tz}

ARM TrustZone\cite{trustzone}是ARM公司为Cortex-A微架构\cite{cortex-a}设计的一种TEE解决方案，其目的是为其产品构建一个安全框架来抵御各种可能的攻击，它通过对原有硬件架构进行修改，在处理器层次引入了两个不同权限的保护域：安全世界(Secure World)和非安全世界(Normal World)，并防止运行于非安全世界的软件直接访问安全世界资源。

如图~\ref{fig:ARM-TZ-base}(a)所示，ARM引入了一种称为监视模式的处理器模式，该模式负责在世界过渡时保留处理器状态，两个世界可以通过称为安全监视器调用(Secure Monitor Call, SMC)的特权指令进入监视模式并实现彼此切换。

\begin{figure}[!htb]
    \small
    \centering
    \begin{tabular}{@{}c@{}c@{}c}
        \includegraphics[width=0.49\textwidth]{ARM-TZ-A.pdf} &
        \hspace{5pt}
        \includegraphics[width=0.49\textwidth]{ARM-TZ-M.pdf}   \\
        \mbox{\small (a) Cortex-A微架构中的TrustZone}        &
        \mbox{\small (b) Cortex-M微架构中的TrustZone}          \\
    \end{tabular}
    \caption{ARM TrustZone技术}
    \label{fig:ARM-TZ-base}
\end{figure}

除了Cortex-A微架构外，ARM发布的新一代Cortex-M微架构\cite{cortex-m}同样为TrustZone提供了硬件支持。与Cortex-A相同的是，Cortex-M依旧将处理器运行状态划分为安全世界和非安全世界，并阻止运行于非安全世界的软件直接访问安全资源。不同的是，Cortex-M针对更快的上下文切换和低功耗应用进行了优化。具体来说，Cortex-M中世界之间的划分是基于内存映射的，并且转换是在异常处理代码中自动发生的(如图~\ref{fig:ARM-TZ-base}(b)所示)。这意味着，当从安全内存运行代码时，处理器处于安全世界，而当从非安全内存运行代码时，处理器处于非安全世界。Cortex-M中的TrustZone技术排除了监视模式，也不需要任何安全的监视软件，这大大减少了安全世界与非安全世界的切换延迟，使得世界之间的转换为更高效。

各芯片产商根据ARM公司对于TrustZone的硬件设计在各自具体的芯片上进行设计和实现，基于TrustZone技术，可以搭建一个可信执行环境(TEE)，并在TEE内运行基于TrustZone的操作系统，如高通的QSEE、开源的OP-TEE等。

\section{本章小结}

本章介绍了普通与加密重复数据删除，现有加密重复数据删除中数据块加密技术和数据所有权证明技术导致的性能问题，以及可信执行环境的相关内容。
